##Data Science Using Scikit-learn

. Supervised Learning:
    ◦ Classification:
        ▪ Decision Trees (DecisionTreeClassifier) 
        ▪ Random Forest (RandomForestClassifier) 
        ▪ Support Vector Machines (SVC)
        ▪ k-Nearest Neighbors (KNeighborsClassifier)
        ▪ Logistic Regression (LogisticRegression)
        ▪ Gradient Boosting (GradientBoostingClassifier) 
    ◦ Regression:
        ▪ Decision Trees (DecisionTreeRegressor) 
        ▪ Random Forest (RandomForestRegressor)
        ▪ Support Vector Machines (SVR)
        ▪ Linear Regression (LinearRegression)
        ▪ Gradient Boosting (GradientBoostingRegressor)
2. Unsupervised Learning:
    ◦ Clustering:
        ▪ K-Means (KMeans)
        ▪ Hierarchical Clustering (AgglomerativeClustering)
        ▪ DBSCAN (DBSCAN)
    ◦ Dimensionality Reduction:
        ▪ Principal Component Analysis (PCA)
        ▪ t-Distributed Stochastic Neighbor Embedding (TSNE)
3. Data Preprocessing:
    ◦ Feature Scaling:
        ▪ StandardScaler
        ▪ MinMaxScaler
    ◦ Imputation:
        ▪ SimpleImputer
    ◦ Encoding:
        ▪ OneHotEncoder
        ▪ LabelEncoder
4. Model Evaluation:
    ◦ Metrics:
        ▪ Accuracy, Precision, Recall, F1-score
        ▪ ROC-AUC
        ▪ Mean Squared Error (for regression)
    ◦ Cross-validation:
        ▪ cross_val_score
        ▪ GridSearchCV and RandomizedSearchCV for hyperparameter tuning
5. Pipelines and Composition:
    ◦ Pipeline
    ◦ FeatureUnion
6. Feature Selection and Extraction:
    ◦ SelectKBest
    ◦ RFE (Recursive Feature Elimination)
7. Text Data:
    ◦ Vectorization:
        ▪ CountVectorizer
        ▪ TfidfVectorizer
    ◦ Transformers:
        ▪ TfidfTransformer
8. Handling Imbalanced Data:
    ◦ Resampling techniques (oversampling, undersampling)
    ◦ Evaluation metrics for imbalanced datasets (precision-recall, F1-score)
9. Advanced Topics:
    ◦ Ensemble Learning:
        ▪ AdaBoost
        ▪ GradientBoostingClassifier/GradientBoostingRegressor
        ▪ XGBoost, LightGBM, CatBoost (external libraries)
    ◦ Support Vector Machines (SVM):
        ▪ SVC, SVR
10. Working with Time Series Data:
    ◦ Feature Engineering:
        ▪ Rolling windows
        ▪ Lag features
11. Understanding Model Internals:
    ◦ Interpretability:
        ▪ Feature importance (tree-based models)
        ▪ Partial dependence plots
12. Deployment and Serialization:
    ◦ Joblib for model serialization
    ◦ Basic understanding of deploying models in a production environment
13. Community and Documentation:
    ◦ Referencing scikit-learn documentation for parameters, methods, and examples
    ◦ Engaging with the scikit-learn community for support and learning
